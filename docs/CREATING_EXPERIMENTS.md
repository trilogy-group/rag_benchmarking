# Creating New Experiments

This project lets you mix different datasets, embedding models, datastores and LLMs. All
experiment definitions live in `src/experiments.py`.

## Steps to Add an Experiment

1. Add a new member to the `ExperimentName` enum describing the experiment.
2. Append an `ExperimentConfig` to the `experiments` list. Supply the dataset,
   datastore, retriever, embedding model and LLM along with `k_values` and any
   limits such as `max_corpus_size`.
3. Run experiments via `make` or by calling `src/main.py` with the new enum name.

### Example

```python
ExperimentConfig(
    name=ExperimentName.PINECONE_FRAME_GEMINI_001_GPT_4O,
    dataset_name="default",
    k_values=[1, 3, 5, 10],
    retriever=PineconeRetriever,
    evaluator=FrameEvaluator,
    datastore=PineconeDatastore,
    dataset=FrameDataset,
    text_embedding_model=GeminiEmbeddingModel.GEMINI_001.value,
    openai_model=OpenAIModel.GPT_4O.value,
    max_corpus_size=200000,
    max_query_count=1000
)
```

## Compatibility Notes

- **Azure AI Search** only works with embeddings generated by Azure OpenAI.
  Gemini embeddings are not supported.
- **Vertex AI** uses a reranking agent that currently requires a Gemini model.
  Nonâ€‘Gemini LLMs cannot be used for reranking.
- **Pinecone** supports two modes:
  - *Native embeddings* &mdash; specify a model like `llama-text-embed-v2` and the
    index computes vectors for you.
  - *Custom embeddings* &mdash; compute vectors yourself and ensure the index
    dimension matches your embedding size.
- **Qdrant** is agnostic to the model, but the configured vector size must match
  your embedding dimension.

Before running an experiment, copy `env.sample` to `.env` and fill in the
required API keys and endpoint settings for the datastore and embedding model
you plan to use.
